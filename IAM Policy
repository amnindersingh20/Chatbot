import logging
import json
import re
import difflib
import uuid
from io import StringIO
import boto3
import pandas as pd
from datetime import datetime, timezone, timedelta

log = logging.getLogger()
log.setLevel(logging.INFO)

# Configuration
S3_BUCKET = "potai"
S3_KEY = "2025.csv"
DYNAMODB_TABLE = "ConversationSessions"
FALLBACK_LAMBDA_NAME = "Poc_Boa1"
BEDROCK_MODEL_ID = "anthropic.claude-3-5-sonnet-2020-v1:0"
SESSION_TTL_MINUTES = 30  # Session expiration time

# AWS Services
_s3 = boto3.client('s3')
_lambda = boto3.client('lambda')
_bedrock = boto3.client("bedrock-runtime", region_name="us-east-1")
_dynamodb = boto3.resource('dynamodb')
session_table = _dynamodb.Table(DYNAMODB_TABLE)

# Enhanced synonym dictionary
SYNONYMS = {
    r"\bco[\s\-]?pay(ment)?s?\b": "copayment",
    r"\bco[\s\-]?insurance\b": "coinsurance",
    r"\b(oop|out[\s\-]?of[\s\-]?pocket)\b": "out of pocket",
    r"\bdeductible(s)?\b": "deductible",
    r"\bmax(imum)?\b": "maximum",
    r"\bmin(imum)?\b": "minimum",
    r"\bin[\s\-]?network\b": "in-network",
    r"\bout[\s\-]?of[\s\-]?network\b": "out-of-network",
    r"\bindividual(s)?\b": "individual",
    r"\bfamily\b": "family",
    r"\bpreventive\b": "preventive",
    r"\bprimary\b": "primary",
    r"\bspecial(ty|ist)?\b": "specialist",
    r"\bemergency\b": "emergency",
    r"\broom\b": "room",
    r"\bhospital\b": "hospital",
    r"\bprescription\b": "prescription",
    r"\bdrug(s)?\b": "drug",
    r"\bphysician\b": "physician",
    r"\bvisit(s)?\b": "visit",
    r"\bcoverage\b": "coverage",
    r"\blimit(s)?\b": "limit",
    r"\bannual\b": "annual",
    r"\blifetime\b": "lifetime",
    r"\bper[\s\-]?visit\b": "per visit",
    r"\bper[\s\-]?occurrence\b": "per occurrence",
    r"\bexclusion(s)?\b": "exclusion",
    r"\bwaiting[\s\-]?period\b": "waiting period",
    r"\btotal\b": "aggregate",
    r"\bsum\b": "aggregate",
    r"\boverall\b": "aggregate",
    r"\bcombined\b": "aggregate"
}

# Core benefit terms for extraction
CORE_BENEFIT_TERMS = {
    'deductible', 'copayment', 'coinsurance', 'out of pocket', 'maximum', 
    'preventive', 'primary', 'specialist', 'emergency', 'hospital', 
    'prescription', 'drug', 'physician', 'visit', 'coverage', 'limit', 'aggregate'
}

FILLER_WORDS = [
    r"\bwhat('?s)?\b", r"\bwhats\b", r"\bwhat is\b", r"\bwhat is the\b",
    r"\bis the\b", r"\btell me\b", r"\bgive me\b", r"\bplease show\b",
    r"\bhelp me with\b", r"\bhelp me to\b", r"\bhow much is\b", r"\bis\b",
    r"\bmy\b", r"\bthe\b", r"\ba\b", r"\ban\b", r"\bfor\b", r"\bof\b",
    r"\bto\b", r"\bin\b", r"\bwith\b", r"\bunder\b", r"\bplan\b", r"\bcoverage\b",
    r"\bamount\b", r"\bcost\b", r"\bvalue\b", r"\bdoes\b", r"\bdo\b", r"\bare\b",
    r"\bcan\b", r"\bcan you\b", r"\bcould\b", r"\bcould you\b", r"\bwould\b",
    r"\bplease\b", r"\bkindly\b", r"\bneed\b", r"\bwant\b", r"\bknow\b", r"\babout\b",
    r"\bdetails\b", r"\binformation\b", r"\bregarding\b", r"\bconcerning\b",
    r"\bpertaining\b", r"\brequired\b", r"\brequirement\b", r"\bbenefit\b",
    r"\bwill\b", r"\bbe\b"
]

# ========================
# UTILITY FUNCTIONS
# ========================
def normalize(text: str) -> str:
    return re.sub(r'[^a-z0-9]', '', str(text).lower())

def tokenize(text: str) -> list:
    text = re.sub(r'[^a-z0-9\s]', ' ', text.lower())
    return re.sub(r'\s+', ' ', text).strip().split()

def strip_filler(text: str) -> str:
    text = text.lower().strip()
    for pat in FILLER_WORDS:
        text = re.sub(pat, '', text)
    return re.sub(r'\s+', ' ', text).strip()

def expand_synonyms(text: str) -> str:
    for pat, rep in SYNONYMS.items():
        text = re.sub(pat, rep, text, flags=re.IGNORECASE)
    return text

def extract_benefit_terms(text: str) -> list:
    expanded = expand_synonyms(text)
    tokens = tokenize(expanded)
    found_terms = []
    
    # Multi-word terms
    for term in sorted(CORE_BENEFIT_TERMS, key=len, reverse=True):
        term_tokens = term.split()
        if all(t in tokens for t in term_tokens):
            found_terms.append(term)
            for t in term_tokens:
                if t in tokens:
                    tokens.remove(t)
    
    # Single-word terms
    for token in tokens:
        if token in CORE_BENEFIT_TERMS:
            found_terms.append(token)
    
    # Special handling for "total" queries
    if not found_terms and any(t in tokens for t in ['total', 'sum', 'overall']):
        found_terms.append('deductible')
    
    return list(set(found_terms))

def semantic_similarity(query_tokens: set, target_tokens: set) -> float:
    if not query_tokens or not target_tokens:
        return 0.0
        
    intersection = query_tokens & target_tokens
    union = query_tokens | target_tokens
    return len(intersection) / len(union) if union else 0.0

# ========================
# DATA LOADING
# ========================
def load_dataframe():
    try:
        obj = _s3.get_object(Bucket=S3_BUCKET, Key=S3_KEY)
        df = pd.read_csv(StringIO(obj['Body'].read().decode('utf-8')), dtype=str)
        
        # Clean data
        df.columns = df.columns.str.strip()
        df['Data Point Name'] = (
            df['Data Point Name'].astype(str)
            .str.replace('–', '-', regex=False)
            .str.replace('\u200b', '', regex=False)
            .str.strip()
            .str.lower()
        )
        
        # Create normalized version for matching
        df['normalized_name'] = df['Data Point Name'].apply(normalize)
        df['tokens'] = df['Data Point Name'].apply(
            lambda x: set(tokenize(expand_synonyms(x)))
        
        return df
    except Exception as e:
        log.exception("Failed to load CSV from S3: %s", str(e))
        return pd.DataFrame()

# Load data once during cold start
DF = load_dataframe()
if not DF.empty:
    log.info("Data loaded successfully. Columns: %s", DF.columns.tolist())
else:
    log.error("Failed to load data. Empty DataFrame")

# ========================
# PLAN DATA LOOKUP
# ========================
def get_plan_value(raw_condition: str, plan_id: str):
    try:
        cleaned = strip_filler(raw_condition)
        expanded = expand_synonyms(cleaned)
        query_norm = normalize(expanded)
        query_tokens = set(tokenize(expanded))
        
        log.info("Lookup trace: raw='%s' → cleaned='%s' → expanded='%s' → norm='%s'",
                 raw_condition, cleaned, expanded, query_norm)

        if DF.empty:
            return 500, "Data not loaded"
            
        if 'Data Point Name' not in DF.columns or plan_id not in DF.columns:
            return 500, f"CSV missing required columns or plan '{plan_id}'"

        # Extract core benefit terms
        benefit_terms = extract_benefit_terms(cleaned)
        log.info("Extracted benefit terms: %s", benefit_terms)
        
        if not benefit_terms:
            benefit_terms = [cleaned]
        
        results = []
        found_terms = set()
        
        # Search for each benefit term
        for term in benefit_terms:
            term_expanded = expand_synonyms(term)
            term_norm = normalize(term_expanded)
            term_tokens = set(tokenize(term_expanded))
            
            # Matching strategies
            exact_match = DF[DF['normalized_name'] == term_norm]
            if not exact_match.empty:
                status, term_data = extract_results(exact_match, plan_id, raw_condition)
                if status == 200:
                    results.extend(term_data)
                    found_terms.add(term)
                    continue

            substring_match = DF[DF['normalized_name'].str.contains(term_norm, na=False)]
            if not substring_match.empty:
                status, term_data = extract_results(substring_match, plan_id, raw_condition)
                if status == 200:
                    results.extend(term_data)
                    found_terms.add(term)
                    continue

            if len(term_tokens) >= 1:
                DF['similarity'] = DF['tokens'].apply(
                    lambda tokens: semantic_similarity(term_tokens, tokens) 
                    if isinstance(tokens, set) else 0.0
                )
                semantic_matches = DF[DF['similarity'] >= 0.4].sort_values(
                    'similarity', ascending=False
                ).head(3)
                
                if not semantic_matches.empty:
                    status, term_data = extract_results(semantic_matches, plan_id, raw_condition)
                    if status == 200:
                        results.extend(term_data)
                        found_terms.add(term)
                        continue

            close = difflib.get_close_matches(
                term_expanded, 
                DF['Data Point Name'].tolist(), 
                n=3, 
                cutoff=0.5
            )
            if close:
                fuzzy_matches = DF[DF['Data Point Name'].isin(close)]
                status, term_data = extract_results(fuzzy_matches, plan_id, raw_condition)
                if status == 200:
                    results.extend(term_data)
                    found_terms.add(term)

        # Special handling for "total" queries
        if 'aggregate' in benefit_terms or 'total' in cleaned.lower():
            deductible_types = [
                'in-network individual deductible',
                'in-network family deductible',
                'out-of-network individual deductible',
                'out-of-network family deductible'
            ]
            
            deductible_results = []
            for dtype in deductible_types:
                match = DF[DF['Data Point Name'] == dtype]
                if not match.empty:
                    status, data = extract_results(match, plan_id, dtype)
                    if status == 200:
                        deductible_results.extend(data)
            
            if deductible_results:
                results.append({
                    "condition": "Aggregate Deductible Information",
                    "plan": plan_id,
                    "value": "SEE BELOW",
                    "details": deductible_results
                })
                found_terms.add('aggregate')

        if results:
            seen = set()
            unique_results = []
            for r in results:
                identifier = (r['condition'], r['plan'])
                if identifier not in seen:
                    seen.add(identifier)
                    unique_results.append(r)
            return 200, unique_results
            
        return 404, f"No values found for '{raw_condition}' under plan '{plan_id}'"

    except Exception as e:
        log.exception("Error during plan value lookup: %s", str(e))
        return 500, f"Processing error: {str(e)}"

def extract_results(matches, plan_id, raw_condition):
    results = []
    for _, row in matches.iterrows():
        val = row.get(plan_id)
        if pd.notna(val) and str(val).strip().lower() not in ['n/a', 'na', 'nan', 'not applicable']:
            results.append({
                "condition": row['Data Point Name'],
                "plan": plan_id,
                "value": val
            })
            
    if results:
        return 200, results
        
    if not matches.empty:
        return 404, f"Plan '{plan_id}' has no value for '{raw_condition}'"
    
    return 404, f"No data points matching '{raw_condition}' found"

# ========================
# SESSION MANAGEMENT
# ========================
def create_session(session_data: dict) -> str:
    session_id = str(uuid.uuid4())
    ttl = int((datetime.now(timezone.utc) + timedelta(minutes=SESSION_TTL_MINUTES)).timestamp()
    
    session_data.update({
        "sessionId": session_id,
        "ttl": ttl,
        "createdAt": datetime.now(timezone.utc).isoformat(),
        "lastAccessed": datetime.now(timezone.utc).isoformat()
    })
    
    try:
        session_table.put_item(Item=session_data)
        return session_id
    except Exception as e:
        log.error("Failed to create session: %s", str(e))
        return ""

def get_session(session_id: str) -> dict:
    try:
        response = session_table.get_item(Key={"sessionId": session_id})
        return response.get("Item", {})
    except Exception as e:
        log.error("Failed to get session: %s", str(e))
        return {}

def update_session(session_id: str, session_data: dict) -> bool:
    ttl = int((datetime.now(timezone.utc) + timedelta(minutes=SESSION_TTL_MINUTES)).timestamp()
    session_data["ttl"] = ttl
    session_data["lastAccessed"] = datetime.now(timezone.utc).isoformat()
    
    try:
        session_table.put_item(Item=session_data)
        return True
    except Exception as e:
        log.error("Failed to update session: %s", str(e))
        return False

def delete_session(session_id: str) -> bool:
    try:
        session_table.delete_item(Key={"sessionId": session_id})
        return True
    except Exception as e:
        log.error("Failed to delete session: %s", str(e))
        return False

# ========================
# NLP & CONVERSATION HANDLING
# ========================
def converse_with_claude(messages: list, context: dict = None) -> str:
    """
    Engage in conversation with Claude using message history
    and optional context data
    """
    try:
        # Prepare system prompt with context
        system_prompt = (
            "You are a helpful and friendly health benefits advisor. "
            "Use the following context to answer questions accurately:"
        )
        
        if context:
            system_prompt += f"\nContext: {json.dumps(context, indent=2)}"
        
        # Structure messages for Claude
        claude_messages = [{"role": "system", "content": system_prompt}]
        
        # Add conversation history
        for msg in messages:
            claude_messages.append({
                "role": "user" if msg["source"] == "user" else "assistant",
                "content": msg["content"]
            })
        
        # Call Claude
        response = _bedrock.invoke_model(
            modelId=BEDROCK_MODEL_ID,
            contentType="application/json",
            accept="application/json",
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31",
                "messages": claude_messages,
                "max_tokens": 2048,
                "temperature": 0.3
            })
        )
        
        body = json.loads(response['body'].read())
        return body['content'][0]['text']
    except Exception as e:
        log.exception("Claude conversation failed: %s", str(e))
        return "I'm having trouble understanding that. Could you rephrase?"

def handle_conversation(session: dict, user_input: str) -> dict:
    """
    Handle conversation flow using session context
    """
    # Initialize session if new
    if not session:
        session = {
            "conversation": [],
            "context": {},
            "state": "new"
        }
    
    # Add user message to conversation
    session["conversation"].append({
        "source": "user",
        "content": user_input,
        "timestamp": datetime.now(timezone.utc).isoformat()
    })
    
    # Determine conversation context
    context = session.get("context", {})
    
    # Handle different conversation states
    if session.get("state") == "awaiting_deductible_info":
        # Continue deductible estimation workflow
        return handle_deductible_workflow(session, user_input)
    
    # Generate response using Claude
    response = converse_with_claude(session["conversation"], context)
    
    # Update conversation
    session["conversation"].append({
        "source": "assistant",
        "content": response,
        "timestamp": datetime.now(timezone.utc).isoformat()
    })
    
    # Detect workflow triggers
    if "estimate" in response.lower() and "deductible" in response.lower():
        session["state"] = "awaiting_deductible_info"
        session["workflow"] = "deductible_estimation"
        session["workflow_step"] = 0
        session["workflow_data"] = []
        
        # Add instructions for user
        response += (
            "\n\nTo estimate your deductible, I'll need some information:\n"
            "1. How many family members are covered under your plan?\n"
            "2. Do you primarily use in-network providers? (yes/no)\n"
            "3. How many doctor visits do you expect this year?"
        )
    
    # Update session
    session["lastAccessed"] = datetime.now(timezone.utc).isoformat()
    
    return {
        "response": response,
        "session": session
    }

def handle_deductible_workflow(session: dict, user_input: str) -> dict:
    """
    Handle multi-step deductible estimation workflow
    """
    workflow_data = session.get("workflow_data", [])
    workflow_step = session.get("workflow_step", 0)
    
    # Collect information based on current step
    if workflow_step == 0:
        # Get number of family members
        try:
            members = int(re.search(r'\d+', user_input).group())
            workflow_data.append({"question": "Family members", "answer": members})
            session["workflow_step"] = 1
            response = "Thank you. Do you primarily use in-network providers? (yes/no)"
        except:
            response = "I couldn't find a number in your response. How many family members are covered?"
    
    elif workflow_step == 1:
        # Get network preference
        if re.search(r'\b(yes|yeah|yep|sure)\b', user_input, re.IGNORECASE):
            workflow_data.append({"question": "Network preference", "answer": "in-network"})
            session["workflow_step"] = 2
            response = "Great! Approximately how many doctor visits do you expect this year?"
        elif re.search(r'\b(no|nope|out of network)\b', user_input, re.IGNORECASE):
            workflow_data.append({"question": "Network preference", "answer": "out-of-network"})
            session["workflow_step"] = 2
            response = "Thanks. Approximately how many doctor visits do you expect this year?"
        else:
            response = "Please answer with 'yes' or 'no': Do you primarily use in-network providers?"
    
    elif workflow_step == 2:
        # Get expected visits
        try:
            visits = int(re.search(r'\d+', user_input).group())
            workflow_data.append({"question": "Expected visits", "answer": visits})
            
            # Perform estimation
            estimate = estimate_deductible(
                session["context"].get("plan_id", ""),
                workflow_data
            )
            
            # Complete workflow
            response = (
                f"Based on your inputs, I estimate your annual deductible will be around {estimate}.\n"
                "Would you like to explore how this compares to other plans?"
            )
            session["state"] = "active"
            session.pop("workflow", None)
            session.pop("workflow_step", None)
            session.pop("workflow_data", None)
        except:
            response = "I couldn't find a number in your response. How many doctor visits do you expect this year?"
    
    # Update session
    session["workflow_data"] = workflow_data
    session["conversation"].append({
        "source": "assistant",
        "content": response,
        "timestamp": datetime.now(timezone.utc).isoformat()
    })
    
    return {
        "response": response,
        "session": session
    }

def estimate_deductible(plan_id: str, responses: list) -> str:
    """Estimate deductible based on user-provided information"""
    # Extract responses
    family_members = 1
    in_network = True
    visits = 0
    
    for r in responses:
        if "Family members" in r["question"]:
            family_members = r["answer"]
        elif "Network preference" in r["question"]:
            in_network = (r["answer"] == "in-network")
        elif "Expected visits" in r["question"]:
            visits = r["answer"]
    
    # Get deductible values
    status, deductible_data = get_plan_value("deductible", plan_id)
    
    if status != 200:
        return "I couldn't retrieve your plan details. Please contact your benefits administrator."
    
    # Simple estimation logic
    try:
        family_members = int(family_members)
        visits = int(visits)
        
        # Find relevant deductibles
        individual_deductible = 0
        family_deductible = 0
        
        for item in deductible_data:
            if "individual deductible" in item["condition"].lower():
                individual_deductible = float(re.sub(r"[^\d.]", "", item["value"]))
            elif "family deductible" in item["condition"].lower():
                family_deductible = float(re.sub(r"[^\d.]", "", item["value"]))
        
        # Calculate estimate
        if family_members == 1:
            estimate = individual_deductible
        else:
            estimate = min(
                individual_deductible * family_members,
                family_deductible
            )
            
        # Adjust based on network usage
        if not in_network:
            estimate *= 1.5  # Simple heuristic
            
        return f"${estimate:,.2f}"
    
    except Exception:
        log.exception("Deductible estimation failed")
        return "an amount that couldn't be calculated. Please consult your plan details."

# ========================
# MAIN LAMBDA HANDLER
# ========================
def wrap_response(status, body):
    return {
        "statusCode": status,
        "headers": {
            "Content-Type": "application/json",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "OPTIONS,POST"
        },
        "body": json.dumps(body, default=str)
    }

def lambda_handler(event, context):
    log.info("Received event: %s", json.dumps(event, default=str))
    
    try:
        # Robust input parsing
        body = {}
        if 'body' in event:
            if isinstance(event['body'], str):
                try:
                    body = json.loads(event['body'])
                except json.JSONDecodeError:
                    log.error("Failed to parse body as JSON: %s", event['body'])
                    return wrap_response(400, {"error": "Invalid JSON format"})
            elif isinstance(event['body'], dict):
                body = event['body']
            else:
                return wrap_response(400, {"error": "Unsupported body type"})
        else:
            # Handle direct invocation (console test)
            body = event
        
        session_id = body.get("sessionId")
        user_input = body.get("input", "")
        
        # Extract parameters from different payload structures
        parameters = body.get("parameters", {})
        if isinstance(parameters, dict):
            # Convert to list of dicts format if needed
            parameters = [{"name": k, "value": v} for k, v in parameters.items()]
        
        # Get or create session
        session = {}
        if session_id:
            session = get_session(session_id)
            if not session:
                log.info("Session not found, creating new session")
                session_id = None
        
        if not session_id:
            # New session - initialize with context
            session = {
                "conversation": [],
                "context": {
                    "availableOptions": body.get("availableOptions", []),
                    "electedOption": body.get("electedOption", {}),
                    "plan_id": next((p["value"] for p in parameters if p.get("name") == "plan"), "")
                },
                "state": "new"
            }
            session_id = create_session(session)
            log.info("Created new session: %s", session_id)
        
        # Handle conversation
        conversation_result = handle_conversation(session, user_input)
        
        # Update session
        updated_session = conversation_result["session"]
        if not update_session(session_id, updated_session):
            log.error("Failed to update session: %s", session_id)
        
        return wrap_response(200, {
            "message": conversation_result["response"],
            "sessionId": session_id
        })
        
    except Exception as e:
        log.exception("Unhandled exception: %s", str(e))
        return wrap_response(500, {
            "error": "Internal server error",
            "details": str(e)
        })
