# File: preprocess.py
# ------------------
# This module handles user input preprocessing before passing to the QA chain.
import re

def preprocess_text(text: str) -> str:
    """
    Clean and normalize user input:
    - Lowercase conversion
    - Strip leading/trailing whitespace
    - Remove multiple spaces
    - Custom replacements or filtering
    """
    cleaned = text.lower().strip()
    cleaned = re.sub(r"\s+", " ", cleaned)
    return cleaned


# File: external_handler.py
# -------------------------
# Handles custom input processing logic. 
# Modify this function with your own business logic.
def handle_input(preprocessed_text: str) -> str:
    # Example: pass-through; extend with NLP or parameter extraction
    return preprocessed_text


# File: lambda_function.py
# ------------------------
import os
import time
import logging
import boto3
from datetime import datetime, timezone
from langchain_aws import ChatBedrock
from langchain_aws.retrievers import AmazonKnowledgeBasesRetriever
from langchain.chains import ConversationalRetrievalChain
from langchain.schema import ChatMessage
from langchain_core.runnables.history import RunnableWithMessageHistory
from preprocess import preprocess_text
from external_handler import handle_input

# Set AWS region via Lambda environment config
REGION = os.getenv("AWS_REGION", "us-east-1")
TABLE_NAME = os.getenv("DDB_TABLE", "POCion")
KNOWLEDGE_BASE_ID = os.getenv("KB_ID", "TGMNY")
MODEL_ID = os.getenv("MODEL_ID", "anthropic.claude-3-5-sonnet-2020-v1:0")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize AWS clients and LangChain components globally (cold start)
session = boto3.Session(region_name=REGION)

class DynamoDBChatHistory:
    def __init__(self, table_name: str, session_id: str, client=None, region=REGION):
        self.table_name = table_name
        self.session_id = session_id
        self.dynamo = client or boto3.client("dynamodb", region_name=region)

    def add_message(self, message: ChatMessage):
        timestamp = int(time.time() * 1000)
        created_at = datetime.now(timezone.utc).isoformat()
        self.dynamo.put_item(
            TableName=self.table_name,
            Item={
                "SessionId": {"S": self.session_id},
                "Timestamp": {"N": str(timestamp)},
                "CreatedAt": {"S": created_at},
                "MessageType": {"S": message.role},
                "Content": {"S": message.content},
            }
        )

    def get_messages(self):
        resp = self.dynamo.query(
            TableName=self.table_name,
            KeyConditionExpression="SessionId = :sid",
            ExpressionAttributeValues={":sid": {"S": self.session_id}},
            ScanIndexForward=True
        )
        return [
            ChatMessage(role=item["MessageType"]["S"], content=item["Content"]["S"])
            for item in resp.get("Items", [])
        ]

# Build LLM & retriever
llm = ChatBedrock(
    model_id=MODEL_ID,
    region_name=REGION,
    client=session.client("bedrock-runtime", region_name=REGION)
)
retriever = AmazonKnowledgeBasesRetriever(
    knowledge_base_id=KNOWLEDGE_BASE_ID,
    retrieval_config={"vectorSearchConfiguration": {"numberOfResults": 10, "overrideSearchType": "HYBRID"}},
    client=session.client("bedrock-agent-runtime", region_name=REGION)
)
qa_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=retriever,
    output_key="answer",
    return_source_documents=True,
    verbose=False
)

# Lambda handler
def lambda_handler(event, context):
    """
    Expects `event` with:
    {
      "session_id": "string",
      "user_input": "string"
    }
    Returns JSON:
    {
      "answer": "...",
      "source_count": int,
      "session_id": "..."
    }
    """
    session_id = event.get("session_id")
    user_input = event.get("user_input", "").strip()

    if not session_id or not user_input:
        return {"statusCode": 400, "body": "Missing session_id or user_input"}

    history = DynamoDBChatHistory(TABLE_NAME, session_id)

    # Preprocess & custom handling
    cleaned = preprocess_text(user_input)
    processed = handle_input(cleaned)
    history.add_message(ChatMessage(role="user", content=processed))

    # Assemble full history
    past_messages = history.get_messages()

    # Invoke QA chain
    runnable = RunnableWithMessageHistory(
        qa_chain,
        lambda _: history,
        input_messages_key="question",
        history_messages_key="chat_history"
    )
    result = runnable.invoke(
        {"question": processed},
        config={"configurable": {"session_id": session_id}}
    )

    answer = result.get("answer", "")
    docs = result.get("source_documents", [])

    history.add_message(ChatMessage(role="assistant", content=answer))

    logger.info("Session %s: returned %d docs", session_id, len(docs))

    return {
        "statusCode": 200,
        "body": {
            "answer": answer,
            "source_count": len(docs),
            "session_id": session_id
        }
    }
