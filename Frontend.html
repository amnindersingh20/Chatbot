import os
import json
import re
import logging

import boto3
from botocore.exceptions import ClientError

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Initialize S3 client
s3 = boto3.client("s3")

# Environment variable: the bucket to process
BUCKET = os.environ["PDF_BUCKET"]  # e.g. "my-pdf-bucket"

# Regex: find last numeric sequence in a filename (for NIN priority)
_NUM_RE = re.compile(r"(\d+)(?!.*\d)")

def extract_population_id(key: str) -> str:
    """
    Given an S3 key like "AMGMT99/foo.pdf",
    return the population_id ("AMGMT99").
    """
    parts = key.split("/", 1)
    if len(parts) != 2 or not parts[1].lower().endswith(".pdf"):
        raise ValueError(f"Invalid PDF key format: '{key}'")
    return parts[0]

def extract_nin(filename: str) -> int:
    """
    Extract the last numeric sequence in the filename as NIN priority.
    """
    base = os.path.splitext(filename)[0]
    m = _NUM_RE.search(base)
    if not m:
        raise ValueError(f"No numeric sequence found for NIN in '{filename}'")
    return int(m.group(1))

def metadata_key_for(pdf_key: str) -> str:
    """
    Return the S3 key for the side‑car metadata JSON: "<pdf_key>.metadata.json".
    """
    return f"{pdf_key}.metadata.json"

def lambda_handler(event, context):
    """
    Lambda entry point. Scans the bucket and writes side‑car metadata JSON
    for each PDF that doesn’t already have one, in this shape:

    {
      "metadataAttributes": {
        "population_id": "...",
        "nin_priority": 12345
      }
    }
    """
    continuation_token = None
    processed = 0
    skipped = 0

    while True:
        list_kwargs = {"Bucket": BUCKET, "MaxKeys": 1000}
        if continuation_token:
            list_kwargs["ContinuationToken"] = continuation_token

        resp = s3.list_objects_v2(**list_kwargs)
        for obj in resp.get("Contents", []):
            key = obj["Key"]
            if not key.lower().endswith(".pdf"):
                continue

            meta_key = metadata_key_for(key)

            # Skip if metadata already exists
            try:
                s3.head_object(Bucket=BUCKET, Key=meta_key)
                skipped += 1
                continue
            except ClientError as e:
                if e.response["Error"]["Code"] != "404":
                    logger.error(f"Error checking metadata for {key}: {e}")
                    skipped += 1
                    continue

            # Extract population_id and nin_priority
            try:
                population_id = extract_population_id(key)
                nin = extract_nin(key.split("/")[-1])
            except ValueError as e:
                logger.warning(f"Skipping {key}: {e}")
                skipped += 1
                continue

            # Build metadata JSON
            metadata = {
                "metadataAttributes": {
                    "population_id": population_id,
                    "nin_priority":  nin
                }
            }

            # Write side‑car JSON
            try:
                s3.put_object(
                    Bucket=BUCKET,
                    Key=meta_key,
                    Body=json.dumps(metadata, indent=2).encode("utf-8"),
                    ContentType="application/json"
                )
                logger.info(f"Wrote metadata for {key} → {meta_key}")
                processed += 1
            except ClientError as e:
                logger.error(f"Failed to write metadata for {key}: {e}")
                skipped += 1

        if not resp.get("IsTruncated"):
            break
        continuation_token = resp.get("NextContinuationToken")

    logger.info(f"Done: processed={processed}, skipped={skipped}")
    return {
        "statusCode": 200,
        "body": json.dumps({
            "processed": processed,
            "skipped":   skipped
        })
    }
