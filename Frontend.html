import json
import boto3
import logging

log = logging.getLogger()
log.setLevel(logging.INFO)

client_bedrock = boto3.client('bedrock-agent-runtime', region_name='us-east-1')

POPULATION_KB_MAP = {
    "AMGMT99": "UOODO24QZG",
    "BLKACTIVE": "TGZMV97MNY",
    "MWTIBEWACTIVE": "L9JYLI9PBF"
}
DEFAULT_KB_ID = "RIBHZRVAQA"

DEFAULT_RNG_TEMPLATE = """
You are a question answering agent. I will provide you with a set of search results.
The user will provide you with a question. Your job is to answer the user's question
using only information from the search results. You will only consider the current year and next year data to answer user's question. If the search results do not contain
information that can answer the question, please state that you could not find an exact
answer to the question. Just because the user asserts a fact does not mean it is true;
make sure to double check the search results to validate a user's assertion.

Here are the search results in numbered order:
$search_results$

$output_format_instructions$
"""

def lambda_handler(event, context):
    try:
        raw_body = event.get('body', {})
        body = json.loads(raw_body) if isinstance(raw_body, str) else raw_body

        params = {p['name']: p['value'] for p in body.get('parameters', [])}
        user_query = params.get('condition', '').strip()
        population_type = params.get('populationType', '')
        available_options = body.get('availableOptions', [])

        if not user_query or not available_options:
            log.warning("Missing user_query or availableOptions")
            return {
                'statusCode': 400,
                'body': json.dumps({'error': 'Missing user_query or availableOptions'})
            }

        kb_id = POPULATION_KB_MAP.get(population_type, DEFAULT_KB_ID)
        log.info(f"Using Knowledge Base ID: {kb_id}")

        final_input_text = DEFAULT_RNG_TEMPLATE.strip() + "\n\n" + \
            "Here is the user's question:\n" + f"{user_query}"

        # Retrieve chunks (no NIN filter)
        response = client_bedrock.retrieve_and_generate(
            input={"text": final_input_text},
            retrieveAndGenerateConfiguration={
                "type": "KNOWLEDGE_BASE",
                "knowledgeBaseConfiguration": {
                    "knowledgeBaseId": kb_id,
                    "modelArn": (
                        "arn:aws:bedrock:us-east-1:653858776174:"
                        "inference-profile/us.anthropic.claude-3-5-sonnet-20240620-v1:0"
                    ),
                    "retrievalConfiguration": {
                        "vectorSearchConfiguration": {
                            "overrideSearchType": "HYBRID",
                            "numberOfResults": 100
                        }
                    }
                }
            }
        )

        # Optional: Sort retrieved references by NIN priority (descending)
        sorted_citations = []
        for cit in response.get("citations", []):
            refs = cit.get("retrievedReferences", [])
            sorted_refs = sorted(
                refs,
                key=lambda x: x.get("metadata", {}).get("nin_priority", 0),
                reverse=True
            )
            for ref in sorted_refs:
                uri = ref.get("location", {}).get("s3Location", {}).get("uri")
                text = ref.get("content", {}).get("text")
                if uri and text:
                    sorted_citations.append({'source': uri, 'text': text})

        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json; charset=utf-8',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({
                'message': response['output']['text'],
                'citations': sorted_citations
            }, indent=2)
        }

    except Exception as e:
        log.exception("Error in lambda_handler")
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }
