#!/usr/bin/env python3
"""
This script compares a pipe-delimited CSV file against a space-delimited TXT file.  
Lines in the TXT file whose fields match any record in the CSV are removed from the output TXT
and also written (verbatim) to a log file for audit/comparison purposes.  
"""
import csv
import argparse


def load_csv_keys(csv_path, delimiter="|"):
    """
    Load a CSV (or any delimited text) into a set of tuple-keys for fast membership testing.
    """
    keys = set()
    with open(csv_path, newline='', encoding='utf-8') as f:
        reader = csv.reader(f, delimiter=delimiter)
        for row in reader:
            # store tuple of fields for fast lookup
            keys.add(tuple(row))
    return keys


def filter_txt(txt_in, txt_out, removed_log, csv_keys):
    """
    Read the space-delimited TXT file line-by-line.
    If its fields-tuple is found in csv_keys, write that line to removed_log;
    otherwise, write it unchanged to txt_out.
    """
    with open(txt_in, 'r', encoding='utf-8') as fin, \
         open(txt_out, 'w', encoding='utf-8') as fout, \
         open(removed_log, 'w', encoding='utf-8') as logf:
        for line in fin:
            # Preserve blank lines exactly
            if line.strip() == "":
                fout.write(line)
                continue

            # Split on whitespace to match CSV fields
            fields = line.strip().split()
            if tuple(fields) in csv_keys:
                # Write removed line verbatim to log
                logf.write(line)
            else:
                # Write original line to output
                fout.write(line)


def main():
    parser = argparse.ArgumentParser(
        description="Filter a TXT by removing lines present in a CSV, logging removed lines."
    )
    parser.add_argument('csv_file', help='Path to the pipe-delimited CSV file')
    parser.add_argument('txt_file', help='Path to the space-delimited TXT file')
    parser.add_argument('output_txt', help='Path for filtered TXT output')
    parser.add_argument('log_file', help='Path where removed lines will be logged')
    args = parser.parse_args()

    # Load CSV keys
    csv_keys = load_csv_keys(args.csv_file)

    # Filter the TXT and log removals
    filter_txt(args.txt_file, args.output_txt, args.log_file, csv_keys)

    print(f"Filtered output written to: {args.output_txt}")
    print(f"Removed lines logged in:    {args.log_file}")


if __name__ == '__main__':
    main()
