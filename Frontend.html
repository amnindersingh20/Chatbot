import json
import boto3
import logging

log = logging.getLogger()
log.setLevel(logging.INFO)

client_bedrock = boto3.client('bedrock-agent-runtime', region_name='us-east-1')

POPULATION_KB_MAP = {
    "AMGMT99": "VY8BRE8SRT",
    "BLKACTIVE": "TGZMV97MNY",
    "MWTIBEWACTIVE": "L9JYLI9PBF"
}
DEFAULT_KB_ID = "RIBHZRVAQA"

# New simple prompt instruction
def build_prompt(user_query: str) -> str:
    return f"Answer the following question based on the knowledge base:\n{user_query.strip()}"


def lambda_handler(event, context):
    try:
        # Parse incoming request
        raw_body = event.get('body', {})
        body = json.loads(raw_body) if isinstance(raw_body, str) else raw_body

        params = {p['name']: p['value'] for p in body.get('parameters', [])}
        user_query = params.get('condition', '').strip()
        population_type = params.get('populationType', '')
        metadata_filters = params.get('metadataFilters', [])  # expect list of {name, values}
        available_options = body.get('availableOptions', [])

        if not user_query or not available_options:
            log.warning("Missing user_query or availableOptions")
            return {
                'statusCode': 400,
                'body': json.dumps({'error': 'Missing user_query or availableOptions'})
            }

        # Select KB based on population type
        kb_id = POPULATION_KB_MAP.get(population_type, DEFAULT_KB_ID)
        log.info(f"Using Knowledge Base ID: {kb_id}")

        # Build the simple prompt
        prompt_text = build_prompt(user_query)

        # Configure retrieval with metadata filters if provided
        retrieval_config = {
            'vectorSearchConfiguration': {
                'overrideSearchType': 'HYBRID',
                'numberOfResults': 100
            }
        }
        if metadata_filters:
            retrieval_config['metadataConfiguration'] = {
                'metadataFilterList': metadata_filters
            }

        # Call Bedrock retrieve-and-generate
        response = client_bedrock.retrieve_and_generate(
            input={'text': prompt_text},
            retrieveAndGenerateConfiguration={
                'type': 'KNOWLEDGE_BASE',
                'knowledgeBaseConfiguration': {
                    'knowledgeBaseId': kb_id,
                    'modelArn': (
                        'arn:aws:bedrock:us-east-1::foundation-model/'
                        'anthropic.claude-3-5-sonnet-20240620-v1:0'
                    ),
                    'retrievalConfiguration': retrieval_config,
                    'generationConfiguration': {
                        'inferenceConfig': {
                            'textInferenceConfig': {
                                'maxTokens': 1024,
                                'temperature': 0.0,
                                'topP': 1.0
                            }
                        }
                    }
                }
            }
        )

        # Extract answer and citations
        answer = response['output']['text']
        citations = []
        for cit in response.get('citations', []):
            for ref in cit.get('retrievedReferences', []):
                uri = ref.get('location', {}).get('s3Location', {}).get('uri')
                text = ref.get('content', {}).get('text')
                if uri and text:
                    citations.append({'source': uri, 'text': text})

        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json; charset=utf-8',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({'message': answer, 'citations': citations}, indent=2)
        }

    except Exception as e:
        log.exception("Error in lambda_handler")
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }
