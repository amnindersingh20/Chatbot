#!/usr/bin/env python3
"""
Compare a pipe-delimited CSV file of employee IDs against a target file (CSV or TXT).
Removes blocks/rows in the target file whose header/first field matches an ID in the CSV.
For TXT: blocks are delimited by lines starting with an 8-digit ID.
For CSV: rows are removed if the first field matches an ID.
Removed data is logged to a separate file.
User specifies which file to filter (csv or txt).
"""
import csv
import argparse
import sys
import re
import os

def load_csv_ids(csv_path, delimiter="|"):
    """
    Load the CSV and build a set of 8-digit employee IDs (first CSV field).
    """
    ids = set()
    with open(csv_path, newline='', encoding='utf-8') as f:
        reader = csv.reader(f, delimiter=delimiter)
        for row in reader:
            if not row:
                continue
            emp_id = row[0].strip()
            if re.fullmatch(r"\d{8}", emp_id):
                ids.add(emp_id)
    print(f"Loaded {len(ids)} employee IDs from CSV: {csv_path}")
    return ids

def filter_txt_by_id(txt_in, txt_out, removed_log, id_set):
    """
    Read the TXT, detect blocks by 8-digit ID at line start, and remove matching blocks.
    Writes removed blocks to log and keeps other lines in output.
    """
    in_remove = False
    total_lines = 0
    removed_lines = 0
    blocks_removed = 0

    id_header_re = re.compile(r"^(?P<id>\d{8})")

    with open(txt_in, 'r', encoding='utf-8') as fin, \
         open(txt_out, 'w', encoding='utf-8') as fout, \
         open(removed_log, 'w', encoding='utf-8') as logf:
        for line in fin:
            total_lines += 1
            m = id_header_re.match(line.strip())
            if m:
                current_id = m.group('id')
                # Decide block removal state for this new block
                if current_id in id_set:
                    in_remove = True
                    blocks_removed += 1
                else:
                    in_remove = False

            if in_remove:
                removed_lines += 1
                logf.write(line)
            else:
                fout.write(line)

    print(f"Processed {total_lines} lines from TXT: {txt_in}")
    print(f"Removed {removed_lines} lines across {blocks_removed} blocks (logged to {removed_log})")
    if removed_lines == 0:
        print("Warning: no lines removed. Check that the TXT headers use 8-digit IDs matching the CSV.", file=sys.stderr)

def filter_csv_by_id(csv_in, csv_out, removed_log, id_set, delimiter="|"):
    """
    Read the CSV, remove rows whose first field matches an ID in id_set.
    Writes removed rows to log and keeps other rows in output.
    """
    total_rows = 0
    removed_rows = 0

    with open(csv_in, newline='', encoding='utf-8') as fin, \
         open(csv_out, 'w', newline='', encoding='utf-8') as fout, \
         open(removed_log, 'w', newline='', encoding='utf-8') as logf:
        reader = csv.reader(fin, delimiter=delimiter)
        writer = csv.writer(fout, delimiter=delimiter)
        log_writer = csv.writer(logf, delimiter=delimiter)
        for row in reader:
            total_rows += 1
            if row and re.fullmatch(r"\d{8}", row[0].strip()) and row[0].strip() in id_set:
                removed_rows += 1
                log_writer.writerow(row)
            else:
                writer.writerow(row)

    print(f"Processed {total_rows} rows from CSV: {csv_in}")
    print(f"Removed {removed_rows} rows (logged to {removed_log})")
    if removed_rows == 0:
        print("Warning: no rows removed. Check that the CSV headers use 8-digit IDs matching the reference CSV.", file=sys.stderr)

def main():
    parser = argparse.ArgumentParser(
        description="Filter blocks/rows by employee ID (first 8 digits), logging removed data."
    )
    parser.add_argument('reference_csv', help='Path to the pipe-delimited CSV of IDs')
    parser.add_argument('target_file', help='Path to the target file (CSV or TXT)')
    parser.add_argument('output_file', help='Path for filtered output')
    parser.add_argument('log_file', help='Path where removed data will be logged')
    parser.add_argument('--target_type', choices=['csv', 'txt'], required=True,
                        help='Type of target file to filter: "csv" or "txt"')
    parser.add_argument('--delimiter', default='|', help='Delimiter for CSV files (default: "|")')
    args = parser.parse_args()

    id_set = load_csv_ids(args.reference_csv, delimiter=args.delimiter)
    if args.target_type == 'txt':
        filter_txt_by_id(args.target_file, args.output_file, args.log_file, id_set)
    elif args.target_type == 'csv':
        filter_csv_by_id(args.target_file, args.output_file, args.log_file, id_set, delimiter=args.delimiter)
    else:
        print("Unknown target type. Use --target_type csv or txt.", file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()
