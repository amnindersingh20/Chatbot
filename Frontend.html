#!/usr/bin/env python3
"""
Compare a pipe-delimited CSV file of employee IDs against a target file (CSV or TXT).
Removes blocks/rows in the target file whose header/first field matches an ID in the CSV.
For TXT: blocks are delimited by lines starting with an 8-digit ID.
For CSV: rows are removed if the first field matches an ID.
Removed data is logged to a timestamped file automatically (no CLI param needed).
User specifies which file to filter (csv or txt).
"""
import csv
import argparse
import sys
import re
from datetime import datetime


def load_csv_ids(csv_path, delimiter="|"):
    """
    Load the CSV and build a set of 8-digit employee IDs (first CSV field).
    Also prints each ID as it’s read.
    """
    ids = set()
    print(f"Loading reference IDs from: {csv_path}")
    with open(csv_path, newline='', encoding='utf-8') as f:
        reader = csv.reader(f, delimiter=delimiter)
        for row in reader:
            if not row:
                continue
            emp_id = row[0].strip()
            if re.fullmatch(r"\d{8}", emp_id):
                if emp_id not in ids:
                    print(f"  -> found ID: {emp_id}")
                ids.add(emp_id)
    print(f"Loaded {len(ids)} unique employee IDs from reference CSV.")
    return ids


def filter_csv_by_id(csv_in, csv_out, removed_log, id_set, delimiter=","):
    """
    Read the CSV, remove rows whose first field matches an ID in id_set.
    Writes removed rows to log and keeps other rows in output.
    Skips a header row if the first field is not an 8-digit ID.
    Prints each first-field value as it’s encountered.
    """
    total_rows = 0
    removed_rows = 0

    print(f"Processing target CSV: {csv_in}")
    with open(csv_in, newline='', encoding='utf-8') as fin, \
         open(csv_out, 'w', newline='', encoding='utf-8') as fout, \
         open(removed_log, 'w', newline='', encoding='utf-8') as logf:
        reader = csv.reader(fin, delimiter=delimiter)
        writer = csv.writer(fout, delimiter=delimiter)
        log_writer = csv.writer(logf, delimiter=delimiter)

        # Handle optional header row
        first_row = next(reader, None)
        if first_row:
            total_rows += 1
            first_field = first_row[0].strip()
            is_numeric = bool(re.fullmatch(r"\d{8}", first_field))
            print(f"First row first field ('{first_field}') is {'numeric' if is_numeric else 'non-numeric'}.")
            if not is_numeric:
                writer.writerow(first_row)
            else:
                # process as data row
                print(f"  -> target ID: {first_field}")
                if first_field in id_set:
                    removed_rows += 1
                    log_writer.writerow(first_row)
                else:
                    writer.writerow(first_row)

        # Process remaining rows
        for row in reader:
            total_rows += 1
            if row:
                field0 = row[0].strip()
                print(f"  -> target ID: {field0}")
                if re.fullmatch(r"\d{8}", field0) and field0 in id_set:
                    removed_rows += 1
                    log_writer.writerow(row)
                    continue
            writer.writerow(row)

    print(f"Processed {total_rows} rows from CSV: {csv_in}")
    print(f"Removed {removed_rows} rows (logged to {removed_log})")
    if removed_rows == 0:
        print("Warning: no rows removed. Check that the CSV headers or data use 8-digit IDs matching the reference CSV.", file=sys.stderr)

# (filter_txt_by_id and main remain unchanged)

# [.. existing filter_txt_by_id and main block ..]
